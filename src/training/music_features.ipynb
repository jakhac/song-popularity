{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import os\r\n",
    "import sys\r\n",
    "from pathlib import Path\r\n",
    "from dotenv import load_dotenv\r\n",
    "from typing import List\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "load_dotenv()\r\n",
    "\r\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))\r\n",
    "\r\n",
    "# only for .ipynb because relative imports don't work\r\n",
    "root_path = (DATA_PATH.parent) \r\n",
    "os.chdir(str(root_path))\r\n",
    " \r\n",
    "import src.database.db_interface as db\r\n",
    "import src.training.plotting as p\r\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "# import models\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Loads the musical features from the database into a dataframe\n",
    "\n",
    "    Returns:\n",
    "        dataframe: the pd dataframe of the musical features\n",
    "    \"\"\"\n",
    "    cnx, cursor = db.connect_to_db(\"spotify_ds\")\n",
    "\n",
    "    query = \"\"\"\n",
    "        SELECT t.duration_ms, t.explict, t.release_year, t.danceability, t.energy, t.key, t.loadness, t.mode, t.speechiness, t.acousticness, t.instrumentalness, t.liveness, t.valence, t.tempo, t.time_signature, t.popularity\n",
    "        FROM tracks AS t\n",
    "        INNER JOIN track_status AS ts\n",
    "        ON t.id == ts.song_id\n",
    "        WHERE ts.song_valid == 1\n",
    "        AND ts.lyrics_stored == 1\n",
    "        AND t.release_year >= 2000;\n",
    "    \"\"\"\n",
    "\n",
    "    return pd.read_sql_query(query, cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classes(popularities: List[int]) -> List[int]:\n",
    "    \"\"\"Scale popularity into classes in [0, 10].\n",
    "\n",
    "    Args:\n",
    "        popularities (List[int]): List of popularity scores in [0, 10]\n",
    "\n",
    "    Returns:\n",
    "        List[int]: List of popularity scores in [0, 10]\n",
    "    \"\"\"\n",
    "\n",
    "    return [int(x / 10) for x in popularities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(clf, X_test, y_test):\n",
    "    # predict on test set\n",
    "    y_predict = clf.predict(X_test)\n",
    "\n",
    "    # print metrics\n",
    "    print(\"Accuracy: \" + str(round(accuracy_score(y_test, y_predict), 4)))\n",
    "    print(\"F1: \" + str(round(f1_score(y_test, y_predict, average=\"weighted\"), 4)))\n",
    "    print(\"Recall: \" + str(round(recall_score(y_test, y_predict, average=\"weighted\"), 4)))\n",
    "    print(\"Precision: \" + str(round(precision_score(y_test, y_predict, average=\"weighted\"), 4)))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # check which labels do not appear in prediction\n",
    "    print(f\"Contained predictions: {set(y_predict)}\")\n",
    "    print(f\"Contained tests: {set(y_test)}\")\n",
    "    set(y_test) - set(y_predict)\n",
    "\n",
    "    return y_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "\n",
    "X = df.values[:, :15]\n",
    "print(df)\n",
    "y = create_classes(df.values[:, 15])\n",
    "print(set(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gaussian Naive Bayes\")\n",
    "gaussian_clf = GaussianNB()\n",
    "\n",
    "# fit the model\n",
    "gaussian_clf.fit(X_train, y_train)\n",
    "\n",
    "result = calculate_metrics(gaussian_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVC\")\n",
    "svc_clf = SVC()\n",
    "\n",
    "# fit the model\n",
    "svc_clf.fit(X_train, y_train)\n",
    "\n",
    "calculate_metrics(svc_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Neural Network\")\n",
    "nn_clf = MLPClassifier()\n",
    "\n",
    "# fit the model\n",
    "nn_clf.fit(X_train, y_train)\n",
    "\n",
    "calculate_metrics(nn_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Neighbours Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"K-Neighbours Classifier\")\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "# fit the model\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "calculate_metrics(knn_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision Trees\")\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# fit the model\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "calculate_metrics(dt_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use different number of trees in forest (comparing different hyperparameters)\n",
    "forest_size = [10,20,50,100]\n",
    "\n",
    "# set seed for random state to get compareable results in every execution (forest randomness)\n",
    "np.random.seed(500)\n",
    "\n",
    "for trees in forest_size:\n",
    "    # set forest size\n",
    "    print(\"Predicting with forest size \" + str(trees))\n",
    "    rf = RandomForestClassifier(n_estimators=trees)\n",
    "\n",
    "    # fit the model\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    result = calculate_metrics(rf, X_test, y_test)\n",
    "    print(\"--------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Dataset Music V1 + unpredicted popularity\"\r\n",
    "x = df[\"explict\"]\r\n",
    "y = df[\"popularity\"]\r\n",
    "p.disp_scatter(x, y, \"explicit\", \"popularity\", title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title(\"Dataset Music V1 + unpredicted popularity\")\n",
    "\n",
    "plt.xlabel(\"popularity\")\n",
    "plt.ylabel(\"song count\")\n",
    "\n",
    "lst = list(df.groupby(\"popularity\"))\n",
    "\n",
    "# plt.stem(list(range(0,100)), list(map(lambda x: len(x[1]),lst)))\n",
    "plt.bar(list(range(0,10)), list(map(lambda x: len(x[1]),pd.DataFrame(y_test).groupby(0, as_index=True))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import src.training.postprocessing as pp\r\n",
    "\r\n",
    "plt.title(\"Dataset Music V1 + predicted popularity\")\r\n",
    "\r\n",
    "plt.xlabel(\"popularity\")\r\n",
    "plt.ylabel(\"song count\")\r\n",
    "\r\n",
    "plt.bar(list(set(result)), list(map(lambda x: x, pd.DataFrame(result).value_counts(sort=False))))\r\n",
    "plt.show()\r\n",
    "\r\n",
    "dummy = [x, y, \"popularity\", \"song_count\", \"Plot Name\"]\r\n",
    "\r\n",
    "m = pp.get_metrics(knn_clf, X_test, y_test)\r\n",
    "p.create_plots(m, [dummy], \"music\")\r\n",
    "\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79c01d956d8d580ff50d5e99a3a6d3d709ffed313f15b1c7fdf81c9e53683cc0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}