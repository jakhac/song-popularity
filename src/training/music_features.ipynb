{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Music Feature Training Notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import os\r\n",
    "import sys\r\n",
    "from pathlib import Path\r\n",
    "from dotenv import load_dotenv\r\n",
    "from typing import List\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "from imblearn.under_sampling import RandomUnderSampler\r\n",
    "from imblearn.over_sampling import RandomOverSampler\r\n",
    "\r\n",
    "load_dotenv()\r\n",
    "\r\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))\r\n",
    "\r\n",
    "# only for .ipynb because relative imports don't work\r\n",
    "root_path = (DATA_PATH.parent) \r\n",
    "os.chdir(str(root_path))\r\n",
    " \r\n",
    "import src.training.plotting as p\r\n",
    "import src.training.postprocessing as pp\r\n",
    "import src.training.pre_training as t\r\n",
    "\r\n",
    "from sklearn.metrics import plot_confusion_matrix\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "\r\n",
    "# import models\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = t.get_music_df()\r\n",
    "\r\n",
    "# df2 = t.get_lyric_df()\r\n",
    "# df = df1.join(df2, on='song_id')\r\n",
    "# df = df1.merge(df2, 'ts.song_id')"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split data (X,y)\n",
    "Split data into sample values and sample classes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "X = df.values[:, :15]\r\n",
    "y = df[\"popularity\"].apply(t.encode_popularity)\r\n",
    "\r\n",
    "# X = df[[\"explict\", \"danceability\", \"energy\", \"loadness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\"]]\r\n",
    "# X = df[[\"danceability\", \"energy\", \"loadness\"]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Over-/Undersampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# sampled and encoded popularity\r\n",
    "X, y = RandomUnderSampler(random_state=42).fit_resample(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PCA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Dimensionality Reduction\r\n",
    "reduce_to = 15\r\n",
    "\r\n",
    "# PCA feature selection (TODO what does this do?)\r\n",
    "cols = pd.DataFrame(X).columns\r\n",
    "\r\n",
    "# Standardization of X\r\n",
    "scaler = StandardScaler()\r\n",
    "scaler.fit(X)\r\n",
    "X = scaler.transform(X)\r\n",
    "\r\n",
    "# apply PCA to X\r\n",
    "pca = PCA(n_components=reduce_to)\r\n",
    "pca.fit(X, y)\r\n",
    "X = pca.transform(X)\r\n",
    "\r\n",
    "print(\"Amount explained:\", sum(pca.explained_variance_ratio_))\r\n",
    "print(\"Amount explained in each PC:\", pca.explained_variance_ratio_)\r\n",
    "\r\n",
    "descr = [\"PC-\" + str(x) for x in range(1, reduce_to + 1)]\r\n",
    "print(pd.DataFrame(pca.components_, columns=cols, index=descr))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Amount explained: 1.0\n",
      "Amount explained in each PC: [0.17174525 0.1236077  0.08762937 0.0784639  0.07533546 0.06928971\n",
      " 0.06548365 0.06183017 0.05993097 0.0532027  0.0487471  0.03715936\n",
      " 0.02962022 0.02671915 0.0112353 ]\n",
      "             0         1         2         3         4         5         6   \\\n",
      "PC-1   0.066951 -0.142523  0.016182 -0.136322 -0.540403 -0.051789 -0.502772   \n",
      "PC-2  -0.316209  0.370659  0.250687  0.511615 -0.230303  0.065664 -0.133010   \n",
      "PC-3   0.000946  0.466824  0.250756 -0.308147 -0.011636  0.028628 -0.023916   \n",
      "PC-4   0.408596 -0.002322 -0.097186  0.169931 -0.019876  0.416773 -0.176336   \n",
      "PC-5   0.434070  0.268508 -0.574625  0.009237 -0.071881 -0.113611  0.020078   \n",
      "PC-6  -0.194087 -0.146877 -0.139770 -0.138351 -0.036911  0.666145  0.088987   \n",
      "PC-7   0.117344  0.129340 -0.383180  0.068245 -0.033486 -0.006737 -0.056369   \n",
      "PC-8  -0.088887 -0.072109 -0.022023  0.158410  0.043683 -0.150780 -0.210180   \n",
      "PC-9   0.090792  0.020391  0.171731  0.136914  0.038521 -0.370761  0.185657   \n",
      "PC-10  0.004383  0.164657  0.159179  0.026561  0.121383  0.432370  0.120979   \n",
      "PC-11  0.632267 -0.050304  0.470111  0.293263 -0.103893  0.105451 -0.012912   \n",
      "PC-12  0.118850 -0.631602  0.159961 -0.123947  0.082903 -0.042225  0.054616   \n",
      "PC-13  0.241875  0.270531  0.214336 -0.461622  0.196154 -0.041285  0.184753   \n",
      "PC-14 -0.008300  0.080068  0.139644 -0.418833 -0.026719  0.004317 -0.559014   \n",
      "PC-15  0.009889  0.013923 -0.025837  0.193712  0.756149  0.003973 -0.493257   \n",
      "\n",
      "             7         8         9         10        11        12        13  \\\n",
      "PC-1   0.145720 -0.178161  0.488387  0.084502 -0.084081 -0.251775 -0.129657   \n",
      "PC-2  -0.091800  0.357920  0.175903 -0.191842 -0.197630  0.264597 -0.195614   \n",
      "PC-3  -0.160215  0.434457  0.023199  0.044707  0.262922 -0.481142  0.275494   \n",
      "PC-4  -0.543275  0.058693 -0.090672  0.490089 -0.074454 -0.020105 -0.146641   \n",
      "PC-5   0.146114  0.243889  0.027098 -0.329239  0.240917 -0.010574 -0.373049   \n",
      "PC-6  -0.219392 -0.075143  0.148959 -0.438086  0.166086  0.103750 -0.003412   \n",
      "PC-7   0.130062  0.184834 -0.037051  0.087895 -0.532277  0.166963  0.501268   \n",
      "PC-8   0.081481  0.123857  0.027730  0.368720  0.626009  0.434781  0.028774   \n",
      "PC-9  -0.340212 -0.166958 -0.135835 -0.084406 -0.164930 -0.162559 -0.402642   \n",
      "PC-10  0.636194  0.013463 -0.138763  0.293551 -0.110719 -0.141511 -0.380743   \n",
      "PC-11  0.172048 -0.125541 -0.061891 -0.311599  0.139261  0.085063  0.305341   \n",
      "PC-12  0.038197  0.693345  0.083630 -0.051742 -0.144929  0.003647 -0.143991   \n",
      "PC-13 -0.066867 -0.073040  0.490189  0.096194 -0.151885  0.489321 -0.113438   \n",
      "PC-14 -0.015416  0.013847 -0.578265 -0.199550 -0.113616  0.274590 -0.149388   \n",
      "PC-15  0.015127 -0.057025  0.271121 -0.166527 -0.050336 -0.195893 -0.003430   \n",
      "\n",
      "             14  \n",
      "PC-1  -0.151502  \n",
      "PC-2   0.106650  \n",
      "PC-3  -0.170977  \n",
      "PC-4   0.122801  \n",
      "PC-5   0.058716  \n",
      "PC-6  -0.377892  \n",
      "PC-7  -0.437069  \n",
      "PC-8  -0.389935  \n",
      "PC-9  -0.620279  \n",
      "PC-10 -0.207151  \n",
      "PC-11 -0.049715  \n",
      "PC-12 -0.027502  \n",
      "PC-13  0.015586  \n",
      "PC-14 -0.010193  \n",
      "PC-15 -0.028255  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Pearson Correlation Coefficient\r\n",
    "pear_corr = df.corr(method='pearson')\r\n",
    "plt.imshow(pear_corr, cmap='hot')\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# TODO copy this to plotting notebook, plot only after PCA/feature selection here\r\n",
    "# TODO use correct X, y values\r\n",
    "# X_1, y_1 = RandomUnderSampler(random_state=42).fit_resample(df, y)\r\n",
    "\r\n",
    "# # Scale features\r\n",
    "# max_db = X_1['loadness'].max()\r\n",
    "# min_db = X_1['loadness'].min()\r\n",
    "# X_1['loadness'] = X_1['loadness'].apply(lambda x: abs(x/40))\r\n",
    "\r\n",
    "# # Drop features with range outside [0, 1]\r\n",
    "# X_1 = pd.DataFrame(X_1).drop(['key', 'time_signature', 'release_year', 'duration_ms', 'tempo'], axis=1)\r\n",
    "\r\n",
    "# fig = plt.figure(figsize = (20, 25))\r\n",
    "# j = 0\r\n",
    "# for i in pd.DataFrame(X_1).columns:\r\n",
    "#     plt.subplot(6, 4, j+1)\r\n",
    "#     j += 1\r\n",
    "\r\n",
    "#     sns.kdeplot(pd.DataFrame(X_1).query(\"popularity == 0\")[i], color='b', label='pop=0')\r\n",
    "#     sns.kdeplot(pd.DataFrame(X_1).query(\"popularity == 1\")[i], color='#000000', label='pop=1')\r\n",
    "#     sns.kdeplot(pd.DataFrame(X_1).query(\"popularity == 2\")[i], color='#ff5959', label='pop=2')\r\n",
    "#     sns.kdeplot(pd.DataFrame(X_1).query(\"popularity == 3\")[i], color='#fffd86', label='pop=3')\r\n",
    "#     sns.kdeplot(pd.DataFrame(X_1).query(\"popularity == 4\")[i], color='#a7e81c', label='pop=4')\r\n",
    "#     sns.kdeplot(pd.DataFrame(X_1).query(\"popularity == 5\")[i], color='#65bf65', label='pop=5')\r\n",
    "#     plt.legend(loc='best')\r\n",
    "#     plt.ylim(0, 17)\r\n",
    "#     plt.xlim(0, 1)\r\n",
    "\r\n",
    "# fig.suptitle('Density Analysis')\r\n",
    "# fig.tight_layout()\r\n",
    "# fig.subplots_adjust(top=0.95)\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train/Test-Split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "    X, y, test_size=0.2, random_state=42\r\n",
    ")\r\n",
    "\r\n",
    "print(X_train.shape)\r\n",
    "print(X_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4868, 15)\n",
      "(1218, 15)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# store classifiers for later plotting\r\n",
    "clf_list = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gaussian Naive Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "gaussian_clf = GaussianNB()\r\n",
    "\r\n",
    "# fit the model\r\n",
    "gaussian_clf.fit(X_train, y_train)\r\n",
    "clf_list.append(gaussian_clf)\r\n",
    "\r\n",
    "pp.print_metrics(gaussian_clf, X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Weighted accuracy: 0.6232\n",
      "Weighted f1: 0.609\n",
      "Weighted recall: 0.6232\n",
      "Weighted precision: 0.653\n",
      "Contained classes in prediction: {0, 1}\n",
      "Contained classes in test: {0, 1}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# svc_clf = SVC()\r\n",
    "\r\n",
    "# # fit the model\r\n",
    "# svc_clf.fit(X_train, y_train)\r\n",
    "# clf_list.append(svc_clf)\r\n",
    "\r\n",
    "# pp.print_metrics(svc_clf, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "nn_clf = MLPClassifier()\r\n",
    "\r\n",
    "# fit the model\r\n",
    "nn_clf.fit(X_train, y_train)\r\n",
    "clf_list.append(nn_clf)\r\n",
    "\r\n",
    "pp.print_metrics(nn_clf, X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Weighted accuracy: 0.6741\n",
      "Weighted f1: 0.674\n",
      "Weighted recall: 0.6741\n",
      "Weighted precision: 0.6756\n",
      "Contained classes in prediction: {0, 1}\n",
      "Contained classes in test: {0, 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "f:\\SmartGit-Repositories\\song-popularity\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-Neighbours Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "knn_clf = KNeighborsClassifier()\r\n",
    "\r\n",
    "# fit the model\r\n",
    "knn_clf.fit(X_train, y_train)\r\n",
    "clf_list.append(knn_clf)\r\n",
    "\r\n",
    "pp.print_metrics(knn_clf, X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Weighted accuracy: 0.6363\n",
      "Weighted f1: 0.6356\n",
      "Weighted recall: 0.6363\n",
      "Weighted precision: 0.6397\n",
      "Contained classes in prediction: {0, 1}\n",
      "Contained classes in test: {0, 1}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Trees"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "dt_clf = DecisionTreeClassifier()\r\n",
    "\r\n",
    "# fit the model\r\n",
    "dt_clf.fit(X_train, y_train)\r\n",
    "clf_list.append(dt_clf)\r\n",
    "\r\n",
    "pp.print_metrics(dt_clf, X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Weighted accuracy: 0.5509\n",
      "Weighted f1: 0.5509\n",
      "Weighted recall: 0.5509\n",
      "Weighted precision: 0.5518\n",
      "Contained classes in prediction: {0, 1}\n",
      "Contained classes in test: {0, 1}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# use different number of trees in forest \r\n",
    "forest_size = [10,50,100,250,500,1000]\r\n",
    "\r\n",
    "# set seed for random state to get compareable results in every execution (forest randomness)\r\n",
    "np.random.seed(500)\r\n",
    "\r\n",
    "for trees in forest_size:\r\n",
    "    # set forest size\r\n",
    "    print(\"Predicting with forest size \" + str(trees))\r\n",
    "    rf = RandomForestClassifier(n_estimators=trees)\r\n",
    "\r\n",
    "    # fit the model\r\n",
    "    rf.fit(X_train, y_train)\r\n",
    "    clf_list.append(rf)\r\n",
    "\r\n",
    "    pp.print_metrics(rf, X_test, y_test)\r\n",
    "    print(\"--------\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicting with forest size 10\n",
      "Weighted accuracy: 0.5895\n",
      "Weighted f1: 0.5861\n",
      "Weighted recall: 0.5895\n",
      "Weighted precision: 0.5898\n",
      "Contained classes in prediction: {0, 1}\n",
      "Contained classes in test: {0, 1}\n",
      "--------\n",
      "\n",
      "Predicting with forest size 50\n",
      "Weighted accuracy: 0.656\n",
      "Weighted f1: 0.656\n",
      "Weighted recall: 0.656\n",
      "Weighted precision: 0.657\n",
      "Contained classes in prediction: {0, 1}\n",
      "Contained classes in test: {0, 1}\n",
      "--------\n",
      "\n",
      "Predicting with forest size 100\n",
      "Weighted accuracy: 0.6617\n",
      "Weighted f1: 0.6614\n",
      "Weighted recall: 0.6617\n",
      "Weighted precision: 0.6643\n",
      "Contained classes in prediction: {0, 1}\n",
      "Contained classes in test: {0, 1}\n",
      "--------\n",
      "\n",
      "Predicting with forest size 250\n",
      "Weighted accuracy: 0.6617\n",
      "Weighted f1: 0.6609\n",
      "Weighted recall: 0.6617\n",
      "Weighted precision: 0.6659\n",
      "Contained classes in prediction: {0, 1}\n",
      "Contained classes in test: {0, 1}\n",
      "--------\n",
      "\n",
      "Predicting with forest size 500\n",
      "Weighted accuracy: 0.6461\n",
      "Weighted f1: 0.6453\n",
      "Weighted recall: 0.6461\n",
      "Weighted precision: 0.65\n",
      "Contained classes in prediction: {0, 1}\n",
      "Contained classes in test: {0, 1}\n",
      "--------\n",
      "\n",
      "Predicting with forest size 1000\n",
      "Weighted accuracy: 0.6576\n",
      "Weighted f1: 0.6567\n",
      "Weighted recall: 0.6576\n",
      "Weighted precision: 0.6622\n",
      "Contained classes in prediction: {0, 1}\n",
      "Contained classes in test: {0, 1}\n",
      "--------\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ensemble"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting \r\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier, BaggingClassifier, HistGradientBoostingClassifier\r\n",
    "\r\n",
    "# ens_clf = VotingClassifier(estimators=[\r\n",
    "#     ('gauss', GaussianNB()), ('knn', KNeighborsClassifier()), ('rf', RandomForestClassifier())\r\n",
    "# ])\r\n",
    "\r\n",
    "ens_clf = AdaBoostClassifier(base_estimator=GaussianNB(), \r\n",
    "    n_estimators=25, random_state=42)\r\n",
    "\r\n",
    "ens_clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "pp.print_metrics(ens_clf, X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Weighted accuracy: 0.5493\n",
      "Weighted f1: 0.5493\n",
      "Weighted recall: 0.5493\n",
      "Weighted precision: 0.5495\n",
      "Contained classes in prediction: {0, 1}\n",
      "Contained classes in test: {0, 1}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Store models to .mdl file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# pp.store_model_to_file(rf, \"rf_size=1000_prec=41\", \"music\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics + Confusion Matrices"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " # generate list of plots for each clf: metrics, cf_matrix, cf_matrix_norm\r\n",
    " p_list = p.generate_model_plots(X_test, y_test, clf_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save/display plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# params\r\n",
    "save_plots = False\r\n",
    "n_cols = 3\r\n",
    "document_title = \"Random Forest up to 2000 trees\"\r\n",
    "document_folder = \"all\" # lyrics, model, artist, all\r\n",
    "\r\n",
    "# save/display plots as jpg\r\n",
    "p.plots_from_list(document_title, p_list, document_folder, cols=n_cols, save=save_plots)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion Matrix for Single Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# assign single classifier\r\n",
    "cf_clf = None\r\n",
    "normalized = \"true\" # \"true\", \"all\" or None\r\n",
    "\r\n",
    "# Confusion matrix\r\n",
    "fig, cax = plt.subplots(figsize=(16, 16)) # subplot for larger size\r\n",
    "cax.set_title(str(cf_clf), fontsize=15)\r\n",
    "plot_confusion_matrix(estimator=cf_clf, X=X_test, y_true=y_test, cmap=plt.cm.Blues,normalize=normalized,values_format=\".2f\",ax=cax)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scatter Plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Params\r\n",
    "sct_title = \"Title\"\r\n",
    "sct_x = None\r\n",
    "sct_xlabel = \"x-label\"\r\n",
    "sct_y = None\r\n",
    "sct_ylabel = \"y-label\"\r\n",
    "\r\n",
    "# show scatter plot\r\n",
    "plt.title(sct_title)\r\n",
    "plt.xlabel(sct_x)\r\n",
    "plt.ylabel(sct_y)\r\n",
    "plt.scatter(sct_x, sct_y, s=5, alpha=0.5)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# add scatter plot to plot list\r\n",
    "p_list.append((plt.scatter, {\"x\": sct_x, \"y\": sct_y, \"s\": 5, \"alpha\": 0.5}, sct_title, sct_xlabel, sct_ylabel))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bar Plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Params\r\n",
    "bar_title = \"Title\"\r\n",
    "bar_x = None\r\n",
    "bar_xlabel = \"x-label\"\r\n",
    "bar_height = None\r\n",
    "bar_ylabel = \"y-label\"\r\n",
    "\r\n",
    "# show bar plot\r\n",
    "plt.title(sct_title)\r\n",
    "plt.xlabel(sct_x)\r\n",
    "plt.ylabel(sct_y)\r\n",
    "plt.bar(sct_x, sct_y)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# add bar plot to plot list\r\n",
    "p_list.append((plt.bar, {\"x\": bar_x, \"height\": bar_height}, bar_title, bar_xlabel, bar_ylabel))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import src.training.postprocessing as pp\r\n",
    "\r\n",
    "# dummy = [x, y, \"popularity\", \"song_count\", \"Plot Name\"]\r\n",
    "\r\n",
    "# m = pp.get_metrics(knn_clf, X_test, y_test)\r\n",
    "\r\n",
    "# plist = [].append((plt.scatter, {\"x\": x,\"y\": y,\"s\": 5, \"alpha\": 0.5}, \"xlabel\", \"ylabel\", \"p_name\"))\r\n",
    "\r\n",
    "# y_lst = list(map(lambda x: len(x[1]),pd.DataFrame(y_test).groupby(0, as_index=True)))\r\n",
    "\r\n",
    "# plist.append((plt.bar, {\"x\": list(range(0,10)),\"height\": y_lst}, \"Dataset Music V1 + unpredicted popularity\", \"popularity\", \"song count\"))\r\n",
    "\r\n",
    "# p.plots_from_list(m, plist, \"music\", \"test_plots_from_list_16\")\r\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7762889cc7ac9bab6d2177d92d49475268501662fac0015d8eb9fc80722ae83"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}