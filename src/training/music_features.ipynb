{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import os\r\n",
    "import sys\r\n",
    "from pathlib import Path\r\n",
    "from dotenv import load_dotenv\r\n",
    "from typing import List\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# RUS\r\n",
    "from collections import Counter\r\n",
    "from sklearn.datasets import make_classification\r\n",
    "from imblearn.under_sampling import RandomUnderSampler\r\n",
    "from imblearn.over_sampling import RandomOverSampler\r\n",
    "\r\n",
    "load_dotenv()\r\n",
    "\r\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))\r\n",
    "\r\n",
    "# only for .ipynb because relative imports don't work\r\n",
    "root_path = (DATA_PATH.parent) \r\n",
    "os.chdir(str(root_path))\r\n",
    " \r\n",
    "import src.training.plotting as p\r\n",
    "import src.training.postprocessing as pp\r\n",
    "import src.training.pre_training as t\r\n",
    "\r\n",
    "from sklearn.metrics import plot_confusion_matrix\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "# import models\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = t.get_music_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values[:, :15]\r\n",
    "y = df[\"popularity\"].apply(t.encode_popularity)\r\n",
    "\r\n",
    "X, y = RandomUnderSampler(random_state=42).fit_resample(X,y)\r\n",
    "# X, y = RandomOverSampler(random_state=42).fit_resample(X,y)\r\n",
    "\r\n",
    "# Plot dist\r\n",
    "fig = plt.figure(figsize=(5,5))\r\n",
    "ax = fig.add_subplot(111)\r\n",
    "ax.set_xlabel(\"popularity\")\r\n",
    "ax.set_ylabel(\"count\")\r\n",
    "ax.set_title(\"Distribution of popularity\")\r\n",
    "plt.bar(list(set(y)), pp.count_distribution(y))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "# original_distr = [plt.bar, {\"x\": list(set(y)), \"height\": list(pd.DataFrame(y).value_counts(sort=False))}, \"popularity classes\", \"sample count\", \"Original distribution of samples regarding popularity\"]\r\n",
    "\r\n",
    "# plots = []\r\n",
    "# plots.append(original_distr)\r\n",
    "\r\n",
    "# draw unifrom sample distribution\r\n",
    "# X, y = RandomUnderSampler(random_state=42).fit_resample(X,y)\r\n",
    "# X, y = RandomOverSampler(random_state=42).fit_resample(X,y)\r\n",
    "\r\n",
    "# uniform_distr = [plt.bar, {\"x\": list(set(y)), \"height\": list(pd.DataFrame(y).value_counts(sort=False))}, \"popularity classes\", \"sample count\", \"Uniform distribution of samples regarding popularity\"]\r\n",
    "\r\n",
    "# plots.append(uniform_distr)\r\n",
    "\r\n",
    "# p.plots_from_list(\"Uniform distribution calc\", plots, \"music\", \"uni_calc_2\")\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "    X, y, test_size=0.2, random_state=42\r\n",
    ")\r\n",
    "\r\n",
    "# print(X_train.shape)\r\n",
    "# print(X_test.shape)\r\n",
    "# print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gaussian Naive Bayes\")\n",
    "gaussian_clf = GaussianNB()\n",
    "\n",
    "# fit the model\n",
    "gaussian_clf.fit(X_train, y_train)\n",
    "\n",
    "pp.print_metrics(gaussian_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"SVC\")\n",
    "# svc_clf = SVC()\n",
    "\n",
    "# # fit the model\n",
    "# svc_clf.fit(X_train, y_train)\n",
    "\n",
    "# pp.print_metrics(svc_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Neural Network\")\n",
    "nn_clf = MLPClassifier()\n",
    "\n",
    "# fit the model\n",
    "nn_clf.fit(X_train, y_train)\n",
    "\n",
    "pp.print_metrics(nn_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Neighbours Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"K-Neighbours Classifier\")\r\n",
    "knn_clf = KNeighborsClassifier()\r\n",
    "\r\n",
    "# fit the model\r\n",
    "knn_clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "pp.print_metrics(knn_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision Trees\")\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# fit the model\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "pp.print_metrics(dt_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use different number of trees in forest (comparing different hyperparameters)\n",
    "forest_size = [10,20,50,100,250,500]\n",
    "\n",
    "# set seed for random state to get compareable results in every execution (forest randomness)\n",
    "np.random.seed(500)\n",
    "\n",
    "for trees in forest_size:\n",
    "    # set forest size\n",
    "    print(\"Predicting with forest size \" + str(trees))\n",
    "    rf = RandomForestClassifier(n_estimators=trees)\n",
    "\n",
    "    # fit the model\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    pp.print_metrics(rf, X_test, y_test)\n",
    "    print(\"--------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Dataset Music V1 + unpredicted popularity\"\n",
    "x = df[\"explict\"]\n",
    "y = df[\"popularity\"]\n",
    "p.disp_scatter(x, y, \"explicit\", \"popularity\", title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.title(\"Dataset Music V1 + unpredicted popularity\")\n",
    "\n",
    "# plt.xlabel(\"popularity\")\n",
    "# plt.ylabel(\"song count\")\n",
    "# plt.bar(list(set(y_predict)),pp.count_distribution(y_predict))\n",
    "# plt.show()\n",
    "y_predict = dt_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\r\n",
    "fig, cax = plt.subplots(figsize=(10,10)) # subplot for larger size\r\n",
    "cax.set_title(\"Random Forest (size 100) Accuracy - Undersampling\", fontsize=15)\r\n",
    "plot_confusion_matrix(estimator=rf, X=X_test, y_true=y_test, cmap=plt.cm.Blues,normalize=None,values_format=\".2f\",ax=cax)\r\n",
    "\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import src.training.postprocessing as pp\n",
    "\n",
    "dummy = [x, y, \"popularity\", \"song_count\", \"Plot Name\"]\n",
    "\n",
    "m = pp.get_metrics(knn_clf, X_test, y_test)\n",
    "\n",
    "plist = [].append((plt.scatter, {\"x\": x,\"y\": y,\"s\": 5, \"alpha\": 0.5}, \"xlabel\", \"ylabel\", \"p_name\"))\n",
    "\n",
    "y_lst = list(map(lambda x: len(x[1]),pd.DataFrame(y_test).groupby(0, as_index=True)))\n",
    "\n",
    "plist.append((plt.bar, {\"x\": list(range(0,10)),\"height\": y_lst}, \"popularity\", \"song count\", \"Dataset Music V1 + unpredicted popularity\"))\n",
    "\n",
    "p.plots_from_list(m, plist, \"music\", \"test_plots_from_list_16\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b3eb31ce1614becdc450ec2390d8c8042f24cf7f310c376c5598f4b488704d2"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}