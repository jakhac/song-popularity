{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lyrics Feature Training Notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import os\r\n",
    "import sys\r\n",
    "from pathlib import Path\r\n",
    "from dotenv import load_dotenv\r\n",
    "from typing import List\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "# import seaborn as sns TODO requirements.txt\r\n",
    "\r\n",
    "from imblearn.under_sampling import RandomUnderSampler\r\n",
    "from imblearn.over_sampling import RandomOverSampler\r\n",
    "\r\n",
    "load_dotenv()\r\n",
    "\r\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))\r\n",
    "\r\n",
    "# only for .ipynb because relative imports don't work\r\n",
    "root_path = (DATA_PATH.parent) \r\n",
    "os.chdir(str(root_path))\r\n",
    " \r\n",
    "import src.training.plotting as p\r\n",
    "import src.training.postprocessing as pp\r\n",
    "import src.training.pre_training as t\r\n",
    "\r\n",
    "from sklearn.metrics import plot_confusion_matrix\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "\r\n",
    "# import models\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = t.get_lyric_df()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split data (X,y)\n",
    "Split data into sample values and sample classes "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df.values[:, :3]\r\n",
    "# X = df[[\"word_count\"]]\r\n",
    "y = df[\"popularity\"].apply(t.encode_popularity)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Over-/Undersampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sampled and encoded popularity\r\n",
    "X, y = RandomUnderSampler(random_state=42).fit_resample(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train/Test-Split\n",
    "No PCA or feature selection, because only 3 features."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "    X, y, test_size=0.2, random_state=42\r\n",
    ")\r\n",
    "\r\n",
    "print(X_train.shape)\r\n",
    "print(X_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# store classifiers for later plotting\r\n",
    "clf_list = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gaussian Naive Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gaussian_clf = GaussianNB()\r\n",
    "\r\n",
    "# fit the model\r\n",
    "gaussian_clf.fit(X_train, y_train)\r\n",
    "clf_list.append(gaussian_clf)\r\n",
    "\r\n",
    "pp.print_metrics(gaussian_clf, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "svc_clf = SVC()\r\n",
    "\r\n",
    "# fit the model\r\n",
    "svc_clf.fit(X_train, y_train)\r\n",
    "clf_list.append(svc_clf)\r\n",
    "\r\n",
    "pp.print_metrics(svc_clf, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nn_clf = MLPClassifier()\r\n",
    "\r\n",
    "# fit the model\r\n",
    "nn_clf.fit(X_train, y_train)\r\n",
    "clf_list.append(nn_clf)\r\n",
    "\r\n",
    "pp.print_metrics(nn_clf, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-Neighbours Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "knn_clf = KNeighborsClassifier()\r\n",
    "\r\n",
    "# fit the model\r\n",
    "knn_clf.fit(X_train, y_train)\r\n",
    "clf_list.append(knn_clf)\r\n",
    "\r\n",
    "pp.print_metrics(knn_clf, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Trees"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dt_clf = DecisionTreeClassifier()\r\n",
    "\r\n",
    "# fit the model\r\n",
    "dt_clf.fit(X_train, y_train)\r\n",
    "clf_list.append(dt_clf)\r\n",
    "\r\n",
    "pp.print_metrics(dt_clf, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# use different number of trees in forest \r\n",
    "forest_size = [10,50,100,250,500,1000]\r\n",
    "\r\n",
    "# set seed for random state to get compareable results in every execution (forest randomness)\r\n",
    "np.random.seed(500)\r\n",
    "\r\n",
    "# store rf classifiers additionally because of overwriting\r\n",
    "rf_clfs = []\r\n",
    "\r\n",
    "for trees in forest_size:\r\n",
    "    # set forest size\r\n",
    "    print(\"Predicting with forest size \" + str(trees))\r\n",
    "    rf = RandomForestClassifier(n_estimators=trees)\r\n",
    "\r\n",
    "    # fit the model\r\n",
    "    rf.fit(X_train, y_train)\r\n",
    "    clf_list.append(rf)\r\n",
    "\r\n",
    "    pp.print_metrics(rf, X_test, y_test)\r\n",
    "    print(\"--------\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting \r\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier, BaggingClassifier, HistGradientBoostingClassifier\r\n",
    "\r\n",
    "# ens_clf = VotingClassifier(estimators=[\r\n",
    "    # ('gauss', gaussian_clf), ('knn', knn_clf), ('rf', rf)\r\n",
    "# ])\r\n",
    "\r\n",
    "ens_clf = BaggingClassifier(base_estimator=GaussianNB(),\r\n",
    "    n_estimators=250, random_state=42)\r\n",
    "\r\n",
    "ens_clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "pp.print_metrics(ens_clf, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Store model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# fig = plt.figure(figsize=(5,5))\r\n",
    "# ax = fig.add_subplot(111)\r\n",
    "# ax.set_title(\"pop distr\")\r\n",
    "# ax.set_xlabel(\"popularity\")\r\n",
    "# ax.set_ylabel(\"count\")\r\n",
    "# plt.bar(list(set(y)), pp.count_distribution(y))\r\n",
    "# print(pd.DataFrame(y).value_counts())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# pp.store_model_to_file(gaussian_clf, \"gauss_prec=31\", \"lyrics\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics + Confusion Matrices"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " # generate list of plots for each clf: metrics, cf_matrix, cf_matrix_norm\r\n",
    " p_list = p.generate_model_plots(X_test, y_test, clf_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save/display plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# params\r\n",
    "save_plots = False\r\n",
    "n_cols = 3\r\n",
    "document_title = \"Random Forest up to 2000 trees\"\r\n",
    "document_folder = \"all\" # lyrics, model, artist, all\r\n",
    "\r\n",
    "# save/display plots as jpg\r\n",
    "p.plots_from_list(document_title, p_list, document_folder, cols=n_cols, save=save_plots)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion Matrix for Single Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# assign single classifier\r\n",
    "cf_clf = gaussian_clf\r\n",
    "normalized = None #\"true\" # \"true\", \"all\" or None\r\n",
    "\r\n",
    "# Confusion matrix\r\n",
    "fig, cax = plt.subplots(figsize=(5, 5)) # subplot for larger size\r\n",
    "cax.set_title(str(cf_clf), fontsize=15)\r\n",
    "plot_confusion_matrix(estimator=cf_clf, X=X_test, y_true=y_test, cmap=plt.cm.Blues,normalize=normalized,values_format=\".2f\",ax=cax)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scatter Plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Params\r\n",
    "sct_title = \"Title\"\r\n",
    "sct_x = None\r\n",
    "sct_xlabel = \"x-label\"\r\n",
    "sct_y = None\r\n",
    "sct_ylabel = \"y-label\"\r\n",
    "\r\n",
    "# show scatter plot\r\n",
    "plt.title(sct_title)\r\n",
    "plt.xlabel(sct_x)\r\n",
    "plt.ylabel(sct_y)\r\n",
    "plt.scatter(sct_x, sct_y, s=5, alpha=0.5)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# add scatter plot to plot list\r\n",
    "p_list.append((plt.scatter, {\"x\": sct_x, \"y\": sct_y, \"s\": 5, \"alpha\": 0.5}, sct_title, sct_xlabel, sct_ylabel))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bar Plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Params\r\n",
    "bar_title = \"Title\"\r\n",
    "bar_x = None\r\n",
    "bar_xlabel = \"x-label\"\r\n",
    "bar_height = None\r\n",
    "bar_ylabel = \"y-label\"\r\n",
    "\r\n",
    "# show bar plot\r\n",
    "plt.title(sct_title)\r\n",
    "plt.xlabel(sct_x)\r\n",
    "plt.ylabel(sct_y)\r\n",
    "plt.bar(sct_x, sct_y)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# add bar plot to plot list\r\n",
    "p_list.append((plt.bar, {\"x\": bar_x, \"height\": bar_height}, bar_title, bar_xlabel, bar_ylabel))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b3eb31ce1614becdc450ec2390d8c8042f24cf7f310c376c5598f4b488704d2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}